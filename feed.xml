<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://riven314.github.io/alexlauwh314/feed.xml" rel="self" type="application/atom+xml" /><link href="https://riven314.github.io/alexlauwh314/" rel="alternate" type="text/html" /><updated>2022-03-31T13:26:16-05:00</updated><id>https://riven314.github.io/alexlauwh314/feed.xml</id><title type="html">Document My Data Science Journey</title><subtitle>An easy to use blogging platform with support for Jupyter Notebooks.</subtitle><entry><title type="html">Quick Guide for Installing NVIDIA Driver, CUDA Toolkit and cuDNN</title><link href="https://riven314.github.io/alexlauwh314/cuda/devops/2022/03/31/Quick-Guide-Install-CUDA.html" rel="alternate" type="text/html" title="Quick Guide for Installing NVIDIA Driver, CUDA Toolkit and cuDNN" /><published>2022-03-31T00:00:00-05:00</published><updated>2022-03-31T00:00:00-05:00</updated><id>https://riven314.github.io/alexlauwh314/cuda/devops/2022/03/31/Quick-Guide-Install-CUDA</id><author><name></name></author><category term="cuda" /><category term="devops" /><summary type="html"><![CDATA[If you need GPU computing for your living, you probably used to install NVIDIA driver, CUDA Toolkit and cuDNN for your machine. The whole procedures are non-trivial and you may feel clueless if something go wrong in the mid. This guide aims to offer you clear instructions with things you should pay attention.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://riven314.github.io/alexlauwh314/images/2022-03-31-Quick-Guide-Install-CUDA/cover.png" /><media:content medium="image" url="https://riven314.github.io/alexlauwh314/images/2022-03-31-Quick-Guide-Install-CUDA/cover.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Paper Summary: “MVSNet: Depth Inference for Unstructured Multi-view Stereo”</title><link href="https://riven314.github.io/alexlauwh314/paper/computer-graphics/2022/03/29/MVSNet.html" rel="alternate" type="text/html" title="Paper Summary: “MVSNet: Depth Inference for Unstructured Multi-view Stereo”" /><published>2022-03-29T00:00:00-05:00</published><updated>2022-03-29T00:00:00-05:00</updated><id>https://riven314.github.io/alexlauwh314/paper/computer-graphics/2022/03/29/MVSNet</id><author><name></name></author><category term="paper" /><category term="computer-graphics" /><summary type="html"><![CDATA[Multi-view stereo has been a well-studied 3D computer vision problem. MVSNet nicely demonstrates how deep learning could interplay with traditional algorithm to better solve this problem. It is an end-to-end deep learning pipeline resembling plane sweeping stereo. It is scalable and significantly outperforms existing models.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://riven314.github.io/alexlauwh314/images/2022-03-29-MVSNet/cover.png" /><media:content medium="image" url="https://riven314.github.io/alexlauwh314/images/2022-03-29-MVSNet/cover.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Paper Summary: “BlockNeRF: Scalable Large Scene Neural View Synthesis”</title><link href="https://riven314.github.io/alexlauwh314/paper/computer-graphics/2022/03/06/BlockNeRF.html" rel="alternate" type="text/html" title="Paper Summary: “BlockNeRF: Scalable Large Scene Neural View Synthesis”" /><published>2022-03-06T00:00:00-06:00</published><updated>2022-03-06T00:00:00-06:00</updated><id>https://riven314.github.io/alexlauwh314/paper/computer-graphics/2022/03/06/BlockNeRF</id><author><name></name></author><category term="paper" /><category term="computer-graphics" /><summary type="html"><![CDATA[NeRF has finally found its place in industrial application! BlockNeRF extends NeRF to reconstruct realistic city map at large scale. It effectively saves the expensive cost of data collection by simulating realistic driving views of diverse scenearios, accelerating the development of autonomous driving.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://riven314.github.io/alexlauwh314/images/2022-03-06-BlockNeRF/cover.png" /><media:content medium="image" url="https://riven314.github.io/alexlauwh314/images/2022-03-06-BlockNeRF/cover.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Survival Guide for Docker &amp;amp; Docker Compose</title><link href="https://riven314.github.io/alexlauwh314/de-zoomcamp/software%20engineering/2022/02/13/DockerSurvivalGuide.html" rel="alternate" type="text/html" title="Survival Guide for Docker &amp;amp; Docker Compose" /><published>2022-02-13T00:00:00-06:00</published><updated>2022-02-13T00:00:00-06:00</updated><id>https://riven314.github.io/alexlauwh314/de-zoomcamp/software%20engineering/2022/02/13/DockerSurvivalGuide</id><author><name></name></author><category term="de-zoomcamp" /><category term="software engineering" /><summary type="html"><![CDATA[You probably know what Docker is and how they are commonly used in practice, but are looking for a quick guide to navigate through the jungle. This article summarises the basics in Docker and Docker Compose to help you get started.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://riven314.github.io/alexlauwh314/images/2022-02-13-DockerSurvivalGuide/cover.png" /><media:content medium="image" url="https://riven314.github.io/alexlauwh314/images/2022-02-13-DockerSurvivalGuide/cover.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Paper Summary: “NeRF++: Analyzing and Improving Neural Radiance Fields”</title><link href="https://riven314.github.io/alexlauwh314/paper/computer-graphics/2022/02/01/NeRF++.html" rel="alternate" type="text/html" title="Paper Summary: “NeRF++: Analyzing and Improving Neural Radiance Fields”" /><published>2022-02-01T00:00:00-06:00</published><updated>2022-02-01T00:00:00-06:00</updated><id>https://riven314.github.io/alexlauwh314/paper/computer-graphics/2022/02/01/NeRF++</id><author><name></name></author><category term="paper" /><category term="computer-graphics" /><summary type="html"><![CDATA[Standard NeRF fails to respect the fidelity of an unbounded scene because its assumptions are too restrictive for scene where objects can be anywhere and background is indispensable. NeRF++ addresses the issue by a smart parameterization of foreground and background with 2 separate networks.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://riven314.github.io/alexlauwh314/images/2022-02-01-NeRF++/cover.png" /><media:content medium="image" url="https://riven314.github.io/alexlauwh314/images/2022-02-01-NeRF++/cover.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>