<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Paper Summary: “NeRF++: Analyzing and Improving Neural Radiance Fields” | Alex Lau’s Blog - Document My Data Science Journey</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Paper Summary: “NeRF++: Analyzing and Improving Neural Radiance Fields”" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Standard NeRF fails to respect the fidelity of an unbounded scene because its assumptions are too restrictive for scene where objects can be anywhere and background is indispensable. NeRF++ addresses the issue by a smart parameterization of foreground and background with 2 separate networks." />
<meta property="og:description" content="Standard NeRF fails to respect the fidelity of an unbounded scene because its assumptions are too restrictive for scene where objects can be anywhere and background is indispensable. NeRF++ addresses the issue by a smart parameterization of foreground and background with 2 separate networks." />
<link rel="canonical" href="https://riven314.github.io/alexlauwh314/paper/computer-graphics/2022/02/01/NeRF++.html" />
<meta property="og:url" content="https://riven314.github.io/alexlauwh314/paper/computer-graphics/2022/02/01/NeRF++.html" />
<meta property="og:site_name" content="Alex Lau’s Blog - Document My Data Science Journey" />
<meta property="og:image" content="https://riven314.github.io/alexlauwh314/images/2022-02-01-NeRF++/cover.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-01T00:00:00-06:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://riven314.github.io/alexlauwh314/images/2022-02-01-NeRF++/cover.png" />
<meta property="twitter:title" content="Paper Summary: “NeRF++: Analyzing and Improving Neural Radiance Fields”" />
<script type="application/ld+json">
{"url":"https://riven314.github.io/alexlauwh314/paper/computer-graphics/2022/02/01/NeRF++.html","@type":"BlogPosting","image":"https://riven314.github.io/alexlauwh314/images/2022-02-01-NeRF++/cover.png","headline":"Paper Summary: “NeRF++: Analyzing and Improving Neural Radiance Fields”","dateModified":"2022-02-01T00:00:00-06:00","datePublished":"2022-02-01T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://riven314.github.io/alexlauwh314/paper/computer-graphics/2022/02/01/NeRF++.html"},"description":"Standard NeRF fails to respect the fidelity of an unbounded scene because its assumptions are too restrictive for scene where objects can be anywhere and background is indispensable. NeRF++ addresses the issue by a smart parameterization of foreground and background with 2 separate networks.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/alexlauwh314/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://riven314.github.io/alexlauwh314/feed.xml" title="Alex Lau's Blog - Document My Data Science Journey" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VH9SQ6TLML"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VH9SQ6TLML');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/alexlauwh314/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/alexlauwh314/">Alex Lau&#39;s Blog - Document My Data Science Journey</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/alexlauwh314/about/">About Me</a><a class="page-link" href="/alexlauwh314/search/">Search</a><a class="page-link" href="/alexlauwh314/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Paper Summary: &quot;NeRF++: Analyzing and Improving Neural Radiance Fields&quot;</h1><p class="page-description">Standard NeRF fails to respect the fidelity of an unbounded scene because its assumptions are too restrictive for scene where objects can be anywhere and background is indispensable. NeRF++ addresses the issue by a smart parameterization of foreground and background with 2 separate networks.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-02-01T00:00:00-06:00" itemprop="datePublished">
        Feb 1, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      11 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/alexlauwh314/categories/#paper">paper</a>
        &nbsp;
      
        <a class="category-tags-link" href="/alexlauwh314/categories/#computer-graphics">computer-graphics</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#1-motivations">1. Motivations</a></li>
<li class="toc-entry toc-h2"><a href="#21-how-could-nerf-possibly-learn-so-well">2.1. How Could NeRF Possibly Learn So Well?</a></li>
<li class="toc-entry toc-h2"><a href="#22-the-answer-lies-on-its-design">2.2. The Answer Lies On Its Design!</a></li>
<li class="toc-entry toc-h2"><a href="#31-nerf-shortcoming-for-modelling-unbounded-scene">3.1. NeRF Shortcoming for Modelling Unbounded Scene</a></li>
<li class="toc-entry toc-h2"><a href="#32-parameterising-background-as-an-inverted-sphere">3.2. Parameterising Background as an Inverted Sphere</a></li>
<li class="toc-entry toc-h2"><a href="#33-finding-x-y-z-from-1r">3.3. Finding $(x’, y’, z’)$ from $1/r$</a></li>
<li class="toc-entry toc-h2"><a href="#4-experimental-results">4. Experimental Results</a></li>
<li class="toc-entry toc-h2"><a href="#5-limitations">5. Limitations</a></li>
<li class="toc-entry toc-h2"><a href="#6-references">6. References</a></li>
</ul><p><img src="/alexlauwh314/images/2022-02-01-NeRF++/cover.png" alt="cover.png"></p>

<h2 id="1-motivations">
<a class="anchor" href="#1-motivations" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Motivations</h2>
<hr>
<p>Thanks to over-parameterization, Neural Radiance Field (NeRF) has strong expressive freedom to describe a 3D scene’s geometry and its radiance. How is it possible to escape from numerous wrong solutions and converge to a correct one?</p>

<p>This is a question captivating authors’ attention. It turns out the anwser lies on some choices of design on NeRF’s structure which implicitly impose a form of regularization on its learning. (I personally find this part irrelevant to their main proposal, but it does offer me a new perspective on NeRF).</p>

<p>Despite such amazing capacity, NeRF has difficulty to learn some kinds of scenes. Unbounded scene is one of them which the authors are trying to address. It has its unique challenges because its background is indispensable to render and objects can be anywhere in the scene.</p>

<p>Standard NeRF doesn’t work well for unbounded scenes because it encloses a scene by a finite volume where it draws samples for volumetric rendering. To address the problem, the authors propose NeRF++ to model foreground and background as 2 separate volumes.</p>

<h2 id="21-how-could-nerf-possibly-learn-so-well">
<a class="anchor" href="#21-how-could-nerf-possibly-learn-so-well" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1. How Could NeRF Possibly Learn So Well?</h2>
<hr>
<p>NeRF is a neural network which describes the geometry (i.e. density) and radiance (i.e. colour) of a 3D scene. By the law of Universal Approximation Theorem, network like this could approximate any continuous functions. With so much expressive freedom empowered by its design, NeRF could possibly go wrong in many ways to overfit to training set without generalizing to novel views, unless we have a dense set of training examples as strong supervision.</p>

<p>The authors did an experiment to illustrate the point. They forced NeRF to learn wrong geometry (i.e. surface of a unit sphere) while supervised its radiance on a set of posed views from lego scene. Despite the fact that its learned geometry is far from lego-like, it manged to explain well on views from training set. Not surprisingly the trained NeRF failed miserably to render any novel views from test set.</p>

<p><img src="/alexlauwh314/images/2022-02-01-NeRF++/shape_radiance_ambiguities.png" alt="shape_radiance_ambiguities.png" title="from the paper"></p>

<p>This study suggests that NeRF’s expressive capacity is clearly overpowered, to a degree that even if it screws up on geometry, it could still fit perfectly to the training views. The authors call this phenomenon “shape-radiance ambiguities”.</p>

<p>But unexpectedly many empirical studies show that NeRF could typically learn the correct geometry and radiance of a 3D scene. It is therefore captivating to ask: How on earth could NeRF learn so well in spite of so much freedom to go wrong?</p>

<h2 id="22-the-answer-lies-on-its-design">
<a class="anchor" href="#22-the-answer-lies-on-its-design" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2. The Answer Lies On Its Design!</h2>
<hr>
<p>It turns out the sanity of NeRF has been secretly safeguarded by some choices of design in its model structure, which implicitly serve as a form of regularisation against its learning. The role of these decisions on model was rarely discussed in previous literatures, and this paper finally takes the chance to reveal it.</p>

<p>The authors conjecture 2 possible decisions on NeRF’s model structure that drives it towards correct geometry and radiance at high chance:</p>

<p><strong>1. Low-frequency Encoding on View Direction</strong></p>

<p>One trick applied by original NeRF is to project both viewing direction $(\theta, \phi)$ and spatial coordinate $(x, y, z)$ into high dimensional space by positional encoding. The encoding is independently cast on each parameter. We could formalize the encoding as $\gamma^{L}(p)$, where $L$ is a hyper-parameter that controls the dimension of its output and input $p$ is bounded by $[-1, 1]$:</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.2500em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msup><mi>γ</mi><mi>L</mi></msup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><msup><mn>2</mn><mn>0</mn></msup><mi>π</mi><mi>p</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy="false">(</mo><msup><mn>2</mn><mn>0</mn></msup><mi>π</mi><mi>p</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><msup><mn>2</mn><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow></msup><mi>π</mi><mi>p</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy="false">(</mo><msup><mn>2</mn><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow></msup><mi>π</mi><mi>p</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{split}

\gamma^{L}(p) = (sin(2^{0}\pi p), cos(2^{0}\pi p), ..., sin(2^{L-1}\pi p), cos(2^{L-1}\pi p))

\end{split}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5513310000000002em;vertical-align:-0.5256655em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0256655000000001em;"><span style="top:-3.1343345em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mord mathnormal">in</span><span class="mopen">(</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">cos</span><span class="mopen">(</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">in</span><span class="mopen">(</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.891331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">cos</span><span class="mopen">(</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.891331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mord mathnormal">p</span><span class="mclose">))</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5256655em;"><span></span></span></span></span></span></span></span></span></span></span></span>

<p>Note that $sin(2^{L-1}\pi p)$ or $cos(2^{L-1}\pi p)$ has higher frequency with increasing $L$, so higher $L$ does not only contribute to higher dimensional space but also higher frequency variation on the output. As a result, positional encoding is conducive for NeRF to learn high-frequency details of a scene. To illustrate the impact of positional encoding on rendering quality, <a href="https://twitter.com/ankurhandos">Ankur Handa</a> has made an excellent visual comparison:</p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">This is a great blog that provides intuitive explanation of the positional encoding used in transformers <a href="https://t.co/x8Mse71ARP">https://t.co/x8Mse71ARP</a><br><br>Unlike RNNs transformers do not have any notion of word order so this positional encoding helps in capturing the order of words in sequence. <a href="https://t.co/2IKJMamNE5">pic.twitter.com/2IKJMamNE5</a></p>— Ankur Handa (@ankurhandos) <a href="https://twitter.com/ankurhandos/status/1251895363478274049?ref_src=twsrc%5Etfw">April 19, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

<p>Now comes the hidden details - viewing direction is encoded by $\gamma^{4}(p)$ while spatial coordinate is encoded by $\gamma^{10}(p)$. This implies that features encoded from viewing direction is not so sensitive to high frequency variation compared against that from spatial coordinate. This favors the view-dependent radiance to be smooth and of low frequency with respect to the change in viewing direction.</p>

<p>Incorrect geometry has to be compensated by high-frequency radiance to explain well on training samples. Such low-frequency encoding on viewing direction makes NeRF struggle on high-frequency radiance, and hence guide it towards correct geometry.</p>

<p><strong>2. Viewing Direction Injected at the Near End of Network</strong></p>

<p>The more layers an input feature has passed through, the more complex pattern it could expresse thanks to compounded compositions of non-linear transformations. While spatial coordinate is fed as an input at the beginning of the network, viewing direction is only appended at almost the end.</p>

<p>This limits the complexity that viewing direction could express as features. But on the flip side, it actually serves as a form of regularization to prevent the view-dependent radiance from going too wild.</p>

<p><img src="/alexlauwh314/images/2022-02-01-NeRF++/nerf_model.png" alt="nerf_model.png" title="from the paper"></p>

<h2 id="31-nerf-shortcoming-for-modelling-unbounded-scene">
<a class="anchor" href="#31-nerf-shortcoming-for-modelling-unbounded-scene" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1. NeRF Shortcoming for Modelling Unbounded Scene</h2>
<hr>

<p>Having said NeRF comes with regularization in its structure, it is not without its shortcomings. One issue that the authors is trying to address is its limitation to model unbounded scenes.</p>

<p>Previous studies typically experimented NeRF on bounded scenes that are properly controlled, where an object of interest is centered at a stage and the posed views are taken at roughly a fixed distance from the object. <a href="https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1">Synthetic Dataset</a> is one of the typical benchmark datasets in point. Such controlled environment makes NeRF easier to learn the scene, but they are far from any representations of scenes we would encounter in real life.</p>

<p><img src="/alexlauwh314/images/2022-02-01-NeRF++/controlled_dataset.png" alt="controlled_dataset.png" title="from original NeRF paper"></p>

<p>In practice scenes are unbounded - there could be more than one object of interest and objects could be anywhere in the scene. In particular, background is an indispensable part of the scene so a model should preserve fidelity of both foreground and background in order to be representative of an unbounded scene.</p>

<p><img src="/alexlauwh314/images/2022-02-01-NeRF++/unbounded_scene.png" alt="unbounded_scene.png" title="from Mip NeRF 360 paper"></p>

<p>All these conditions impose significant challenges to standard NeRF. It is caused by the setting that during volumetric rendering standard NeRF samples 3D points from a packed volume. It works well for controlled environment because we know where the object lies, but for unbounded scenes the volume is unlikely to capture most objects from background. The consequence is a blurry background thanks to insufficient sampling of objects from background.</p>

<p>One remedy is to extend the length of the interval in a hope to cover most objects for sampling, but doing so has several practical limitations. If we fix the number of samples per traced ray, the rendered would look blurry in overall because of insufficient samples assigned to both foreground and background. But if we increase the number of samples, it significantly ramps up the computational cost which makes both training and rendering much more time-consuming. On top of that, it would be numerically unstable to evaluate points at far distance from the viewer.</p>

<p>To validate the claim, the authors have shown from experiment that standard NeRF struggles to render views of high fidelity in an unbounded Truck scene.</p>

<p><img src="/alexlauwh314/images/2022-02-01-NeRF++/struggle_on_unbounded_scene.png" alt="struggle_on_unbounded_scene.png" title="from the paper"></p>

<h2 id="32-parameterising-background-as-an-inverted-sphere">
<a class="anchor" href="#32-parameterising-background-as-an-inverted-sphere" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2. Parameterising Background as an Inverted Sphere</h2>
<hr>
<p>The authors propose NeRF++ to address the issue. Its model structure is the same as standard NeRF, except that it segregates foreground and background of a scene into 2 separate networks:</p>
<ul>
  <li>Inner NeRF learns the foreground enclosed by a volume of unit sphere centered at origin</li>
  <li>Outer NeRF learns the background enclosed by a volume of its complement (i.e. an inverted sphere).</li>
</ul>

<p>With such segregation, volumetric rendering has to take into account constitutes from both foreground and background along a traced ray in order to render colour for a pixel $\bold{C}(\bold{r})$. If we denote $t’$ as the time that the traced ray crosses the boundary between the two volumes, its theoretical formulation can expressed as follows:</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.2500em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="bold">C</mi><mo stretchy="false">(</mo><mi mathvariant="bold">r</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msubsup><mo>∫</mo><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><msup><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msubsup><mi>σ</mi><mo stretchy="false">(</mo><mi mathvariant="bold">o</mi><mo>+</mo><mi>t</mi><mi mathvariant="bold">d</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi mathvariant="bold">c</mi><mo stretchy="false">(</mo><mi mathvariant="bold">o</mi><mo>+</mo><mi>t</mi><mi mathvariant="bold">d</mi><mo separator="true">,</mo><mi mathvariant="bold">d</mi><mo stretchy="false">)</mo><mo>⋅</mo><msup><mi>e</mi><mrow><mo>−</mo><msubsup><mo>∫</mo><mrow><mi>s</mi><mo>=</mo><mn>0</mn></mrow><mi>t</mi></msubsup><mi>σ</mi><mo stretchy="false">(</mo><mi mathvariant="bold">o</mi><mo>+</mo><mi>s</mi><mi mathvariant="bold">d</mi><mo stretchy="false">)</mo><mi>d</mi><mi>s</mi></mrow></msup><mi>d</mi><mi>t</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><msubsup><mo>∫</mo><mrow><mi>s</mi><mo>=</mo><mn>0</mn></mrow><msup><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msubsup><mi>σ</mi><mo stretchy="false">(</mo><mi mathvariant="bold">o</mi><mo>+</mo><mi>s</mi><mi mathvariant="bold">d</mi><mo stretchy="false">)</mo><mi>d</mi><mi>s</mi></mrow></msup><msubsup><mo>∫</mo><mrow><mi>t</mi><mo>=</mo><msup><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><mi mathvariant="normal">∞</mi></msubsup><mi>σ</mi><mo stretchy="false">(</mo><mi mathvariant="bold">o</mi><mo>+</mo><mi>t</mi><mi mathvariant="bold">d</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi mathvariant="bold">c</mi><mo stretchy="false">(</mo><mi mathvariant="bold">o</mi><mo>+</mo><mi>t</mi><mi mathvariant="bold">d</mi><mo separator="true">,</mo><mi mathvariant="bold">d</mi><mo stretchy="false">)</mo><mo>⋅</mo><msup><mi>e</mi><mrow><mo>−</mo><msubsup><mo>∫</mo><mrow><mi>s</mi><mo>=</mo><msup><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><mi>t</mi></msubsup><mi>σ</mi><mo stretchy="false">(</mo><mi mathvariant="bold">o</mi><mo>+</mo><mi>s</mi><mi mathvariant="bold">d</mi><mo stretchy="false">)</mo><mi>d</mi><mi>s</mi></mrow></msup><mi>d</mi><mi>t</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{split}

\bold{C}(\bold{r}) &amp; = \int^{t'}_{t=0} \sigma(\bold{o}+t\bold{d}) \cdot \bold{c}(\bold{o}+t\bold{d}, \bold{d}) \cdot e^{-\int^{t}_{s=0} \sigma(\bold{o}+s\bold{d})ds} dt \\
&amp; + e^{-\int^{t'}_{s=0} \sigma(\bold{o}+s\bold{d})ds} \int^{\infty}_{t=t'} \sigma(\bold{o}+t\bold{d}) \cdot \bold{c}(\bold{o}+t\bold{d}, \bold{d}) \cdot e^{-\int^{t}_{s=t'} \sigma(\bold{o}+s\bold{d})ds} dt \\

\end{split}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:5.530571999999999em;vertical-align:-2.5152859999999997em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.0152859999999997em;"><span style="top:-5.015286em;"><span class="pstrut" style="height:3.69238em;"></span><span class="mord"><span class="mord mathbf">C</span><span class="mopen">(</span><span class="mord mathbf">r</span><span class="mclose">)</span></span></span><span style="top:-2.389044em;"><span class="pstrut" style="height:3.69238em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.5152859999999997em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.0152859999999997em;"><span style="top:-5.015286em;"><span class="pstrut" style="height:3.69238em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6923800000000002em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119499999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathbf">o</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">t</span><span class="mord mathbf">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathbf">c</span><span class="mopen">(</span><span class="mord mathbf">o</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">t</span><span class="mord mathbf">d</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathbf">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0370400000000002em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8914857142857143em;"><span style="top:-2.1224514285714284em;margin-left:-0.19445em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-2.9521428571428574em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.37754857142857146em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">σ</span><span class="mopen mtight">(</span><span class="mord mathbf mtight">o</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">s</span><span class="mord mathbf mtight">d</span><span class="mclose mtight">)</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">s</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span></span></span><span style="top:-2.389044em;"><span class="pstrut" style="height:3.69238em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.2092800000000001em;"><span style="top:-3.20928em;margin-right:0.05em;"><span class="pstrut" style="height:2.7962800000000003em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1375428571428574em;"><span style="top:-2.3078514285714284em;margin-left:-0.19445em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.6854em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.137542857142857em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.6854em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9595600000000001em;"><span style="top:-2.9595599999999997em;margin-right:0.1em;"><span class="pstrut" style="height:2.55556em;"></span><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.37754857142857146em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">σ</span><span class="mopen mtight">(</span><span class="mord mathbf mtight">o</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">s</span><span class="mord mathbf mtight">d</span><span class="mclose mtight">)</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">s</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.414292em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119499999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathbf">o</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">t</span><span class="mord mathbf">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathbf">c</span><span class="mopen">(</span><span class="mord mathbf">o</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">t</span><span class="mord mathbf">d</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathbf">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0370400000000002em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8914857142857143em;"><span style="top:-2.2292799999999997em;margin-left:-0.19445em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.6068285714285713em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8495600000000001em;"><span style="top:-2.84956em;margin-right:0.1em;"><span class="pstrut" style="height:2.55556em;"></span><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.0589714285714287em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.6068285714285713em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.37754857142857146em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">σ</span><span class="mopen mtight">(</span><span class="mord mathbf mtight">o</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">s</span><span class="mord mathbf mtight">d</span><span class="mclose mtight">)</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">s</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.5152859999999997em;"><span></span></span></span></span></span></span></span></span></span></span></span>

<p>The former term is numerical rendering of foreground and the latter term is that of background.</p>

<p>One caveat that deviates NeRF++ from the above formula is that outer NeRF receives different inputs than inner NeRF. Same as standard NeRF, inner NeRF is parameterized to return density $\sigma_{in}(\bold{x})$ and colour $\bold{c}_{in}(\bold{x}, \bold{d})$ for a spatial coordinate $\bold{x}$ at viewing direction $\bold{d}$. However, outer NeRF is parameterized slightly different: instead of treating target coordinate $\bold{x}$ as input, it firsly projects $\bold{x}$ onto the unit sphere to yield coordinate $\bold{x’} = (x’, y’, z’)$. And then it takes $\bold{x’}$ and the inverse of target coordinate’s distance $1/r$ as input. As a result, its outputs are parameterized as $\sigma_{out}(\bold{x’}, 1/r)$ and $\bold{c}_{out}(\bold{x’}, 1/r, \bold{d})$.</p>

<p>I personally find such parameterization clever because it skillfully normalises an unbounded spatial coordinate to bounded quantities. Such normalisation helps network to learn the background scene more efficiently. In addition, transforming unbounded inputs to bounded ones help avoid numerical unstability in optimization.</p>

<h2 id="33-finding-x-y-z-from-1r">
<a class="anchor" href="#33-finding-x-y-z-from-1r" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3. Finding $(x’, y’, z’)$ from $1/r$</h2>
<hr>
<p>I think it is worth some space to explain how we could find $(x’, y’, z’)$ and $1/r$.</p>

<p>Let’s say we have a traced ray $\bold{r}(t) = \bold{o} + t \bold{d}$ marching from the inner volume through the outer volume. We start off by randomly sample $1/r$ from the interval $(0, 1)$. The value of $r$ (note that this $r$ is different from the traced ray $\bold{r}(t)$!) should determine the target coordinate $\bold{x}$ that we want: it is the point that lies on the traced ray at a distance of $r$ from the origin. With $\bold{x}$ we could therefore find its projection onto the unit sphere.</p>

<p>While the above intuition should work in principle, there is a simpler approach to find $(x’, y’, z’)$, as follows:</p>
<ol>
  <li>Let $\bold{b} = \bold{o} + t_{b} \bold{d}$ to be the vector that is perpendicular to the traced ray. Find $\bold{b}$ by solving the equation $\bold{d} \cdot (\bold{o}+t_{b} \bold{d}) = 0$ for $t_{b}$</li>
  <li>Let $\bold{a} = \bold{o} + t_{a} \bold{d}$ to be the vector intersecting the unit sphere and the traced ray. Find $\bold{a}$ by solving the equation $\Vert \bold{o} + t_{a} \bold{d} \Vert = 1 $ for $t_{a}$</li>
  <li>Let $\theta$ be the angle between $\bold{a}$ and the traced ray. Find $\theta$ by solving $sin(\theta) = \Vert \bold{b} \Vert$</li>
  <li>Let $\phi$ be the angle between the target coordinate $\bold{x}$ and the traced ray. Find $\phi$ by solving $sin(\phi) = \Vert \bold{b} \Vert / r$</li>
</ol>

<p>Finally we get $\omega = \theta - \phi$. This is the clockwise rotational angle along the plane $\bold{b} \times \bold{a}$ that we can apply to $\bold{a}$ in order to make it aligned to the target projection $(x’, y’, z’)$! One merit of this approach is that when $r$ is updated, we only need to simply update $\phi$ and $\omega$ in order to apply another round of angular rotation on $\bold{a}$!</p>

<p>The geometry of this approach can be neatly visualized below. Note that I draw the geometry in 2D (instead of 3D) just for the convenience of illustration:</p>

<p><img src="/alexlauwh314/images/2022-02-01-NeRF++/inverted_sphere.png" alt="inverted_sphere.png"></p>

<h2 id="4-experimental-results">
<a class="anchor" href="#4-experimental-results" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Experimental Results</h2>
<hr>
<p>NeRF++ managed to render views that look sharp in both foreground and background. In comparison, background rendered by NeRF looks particularly blurry. Below are some experimental results for the scenes taken from Tanks and Temples benchmark dataset:</p>

<p><img src="/alexlauwh314/images/2022-02-01-NeRF++/results.png" alt="results.png" title="from the paper"></p>

<p>The diagram below shows that the proposed parameterisation done by NeRF++ has faithfully segregated foreground from background, without sacrificing the overall fidelities of the Truck scene.</p>

<p><img src="/alexlauwh314/images/2022-02-01-NeRF++/segregation.png" alt="segregation.png" title="from the paper"></p>

<p>Below are quantitative comparison on the same dataset. We can clearly notice that NeRF++ significantly outperforms NeRF for all scenes and all metrics.</p>

<p>As a remark, LPIPS stands for Learned Perceptual Image Patch Similarity which captures differences between image patches (lower means better) and
SSIM stands for Structural Similarity, which captures perceptual similarity between 2 images.</p>

<p><img src="/alexlauwh314/images/2022-02-01-NeRF++/table.png" alt="table.png" title="from the paper"></p>

<h2 id="5-limitations">
<a class="anchor" href="#5-limitations" aria-hidden="true"><span class="octicon octicon-link"></span></a>5. Limitations</h2>
<hr>

<ul>
  <li>
<strong>Higher Computational Cost:</strong> NeRF++ is more costly on training and rendering than standard NeRF. It takes ~24 hours with 4 RTX 2080 Ti GPUs to train NeRF++ and ~30 seconds to render a single 1280x720 image.</li>
  <li>
<strong>Ignorance to Photometric Effect:</strong> Though not a issue specific to NeRF++, it doesn’t take into account unexpected photometric effects such as auto-exposure, vignetting caused by a camera. These effects may contaminate the training samples because it leads to views of different colours even at the same pose, which breaks an assumption imposed on NeRF: same colour should be rendered at same pose.</li>
</ul>

<h2 id="6-references">
<a class="anchor" href="#6-references" aria-hidden="true"><span class="octicon octicon-link"></span></a>6. References</h2>
<hr>
<ol>
  <li><a href="https://arxiv.org/abs/2010.07492">NeRF++: Analyzing and Improving Neural Radiance Fields</a></li>
  <li><a href="https://www.youtube.com/watch?v=Rd0nBO6--bM">Vladlen Koltun: Towards Photorealism (September 2020)</a></li>
  <li><a href="https://arxiv.org/abs/2003.08934">NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</a></li>
</ol>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="riven314/alexlauwh314"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/alexlauwh314/paper/computer-graphics/2022/02/01/NeRF++.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/alexlauwh314/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/alexlauwh314/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/alexlauwh314/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/alexlauwh314/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/alexlauwh314/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
